{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd483630",
   "metadata": {},
   "source": [
    "*KNOWLEDGE BASE EXAMPLES*\n",
    "===\n",
    "- [0.PRINT TRICKS](#0.PRINT-TRICKS)\n",
    "- [1.PREPROCESSING](#1.PREPROCESSING)\n",
    "    - [1.1 ONE HOT ENCODING](#1.1-ONE-HOT-ENCODING)\n",
    "    - [1.2 NORMALIZATION](#1.2-NORMALIZATION)\n",
    "    - [1.3 PCA](#1.3-PCA)\n",
    "    - [1.4 FEATURE IMPORTANCE](#1.4-FEATURE-IMPORTANCE)\n",
    "- [2.FILE MANAGEMENT](#2.FILE-MANAGEMEMT)\n",
    "- [3.PROCESS AND MEMORY MANAGEMENT](3.#PROCESS-AND-MEMORY-MANAGEMENT)\n",
    "- [4.DATA SHAPE MANAGEMENT](#4.DATA-SHAPE-MANAGEMENT)\n",
    "- [5.CORRELATION HEATMAPS](#5.CORRELATION-HEATMAPS)\n",
    "- [6.STRING MANAGEMENT](#6.STRING-MANAGEMENT)\n",
    "- [7.PLOT FUNCTIONS](#7.PLOT-FUNCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae6f49",
   "metadata": {},
   "source": [
    "0.PRINT TRICKS\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variable value: {}\".format(variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c296e5",
   "metadata": {},
   "source": [
    "1.PREPROCESSING\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ebdfa",
   "metadata": {},
   "source": [
    "1.1 ONE HOT ENCODING\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f22478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING WITH OneHoteEncoder\n",
    "categorical_cols = ['Pclass', 'Sex' , 'CabinDeck', 'Embarked', 'Title', 'TicketType']\n",
    "labeled_df = df_data_6[categorical_cols]\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(labeled_df)\n",
    "\n",
    "onehotlabels = enc.transform(labeled_df).toarray()\n",
    "\n",
    "new_columns=list()\n",
    "for col, values in zip(labeled_df.columns, enc.categories_):\n",
    "    new_columns.extend([col + '_' + str(value) for value in values])\n",
    "\n",
    "df_data_8= pd.concat([df_data_6, pd.DataFrame(onehotlabels, columns=new_columns)], axis='columns')\n",
    "df_data_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING WITH getdummies\n",
    "df_data_7=df_data_6.copy()\n",
    "for fname in categorical_cols: \n",
    "    dummy_gender = pd.get_dummies(df_data_7[fname], prefix='{}_'.format(fname))\n",
    "    df_data_7= pd.concat([df_data_7,dummy_gender], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d3b9d",
   "metadata": {},
   "source": [
    "1.2 NORMALIZATION\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9eb7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cMMS=preprocessing.MinMaxScaler()\n",
    "x = df_data_7['SplitFare'].values.reshape(-1, 1)\n",
    "x_scaled = cMMS.fit_transform(x)\n",
    "df_scaled = pd.DataFrame(x_scaled , columns =[\"SplitFareNorm\"]) \n",
    "df_data_9= pd.concat([df_data_7, df_scaled ], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293a293",
   "metadata": {},
   "source": [
    "1.3 PCA\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78383b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_train = \n",
    "n_components = 4\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e519222",
   "metadata": {},
   "source": [
    "1.4 FEATURE IMPORTANCE\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier( n_estimators = 400,\n",
    "                              max_depth = 10,\n",
    "                              max_features = \"log2\",\n",
    "                              criterion = \"gini\",\n",
    "                              min_samples_split = 10,\n",
    "                              min_impurity_decrease = 0.01,\n",
    "                              bootstrap = False ,\n",
    "                              random_state = 2)\n",
    "\n",
    "RFC.fit(x_train, y_train)\n",
    "# get importance\n",
    "importance = RFC.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "dimensions = (14, 8)\n",
    "fig, ax = plt.subplots(figsize=dimensions)\n",
    "ax.bar([x for x in range(len(importance))], importance)\n",
    "plt.xticks(range(x_train.shape[1]), x_train.columns , rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aba50f",
   "metadata": {},
   "source": [
    "2.FILE MANAGEMENT\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21148b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_dataframe.to_pickle(\"a_file.pkl\")\n",
    "output = pd.read_pickle(\"a_file.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La scrittura wb serve perchè pickle scrive in byte non stringhe\n",
    "f = open(\"x_train.pkl\", \"wb\")\n",
    "pickle.dump(x_train, f)\n",
    "f.close()\n",
    "pickle_data = (pickle.load(open(\"x_train.pkl\")))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe to feather file\n",
    "sTempFilePath = './tmp/df_FareResult_4.ftr'\n",
    "os.makedirs('./tmp',exist_ok=True)\n",
    "df_FareResult_4.to_feather(sTempFilePath)\n",
    "\n",
    "#load dataframe from feather file\n",
    "df_FareResult_4=pd.read_feather(sTempFilePath, columns=None, use_threads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d9325",
   "metadata": {},
   "source": [
    "3.PROCESS AND MEMORY MANAGEMENT\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_data_1\n",
    "del df_data_2\n",
    "del df_data_3\n",
    "del df_data_4\n",
    "del df_data_5\n",
    "del df_data_6\n",
    "del df_data_7\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ce4abb",
   "metadata": {},
   "source": [
    "4.DATA SHAPE MANAGEMENT\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2554bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new dimension on array data\n",
    "np_y_train = y_train[:, np.newaxis]\n",
    "np_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5316f0",
   "metadata": {},
   "source": [
    "5.CORRELATION HEATMAPS\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701ed02",
   "metadata": {},
   "source": [
    "5.1 Pearson\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6eef7",
   "metadata": {},
   "source": [
    "La correlazione di Pearson è utilizzabile con due assunzioni:\n",
    "<ul>\n",
    "   <li>la distribuzione dei dati è gaussiana</li>\n",
    "    <li>la rappresentazione cartesiana è <b>lineare</b></li>\n",
    "</ul> \n",
    "Quindi il primo punto debole di questa correlazione è che un legame non lineare viene interpretato come correlazione 0!\n",
    "E' il tipo di correlazione più semplice e basato sulla relazione: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5297e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "![PearsonCorr.jpg](attachment:PearsonCorr.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05410b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = pd.DataFrame(df_data_1.corr(method='pearson'))\n",
    "mask=np.zeros_like(df_heatmap)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f,ax = plt.subplots(figsize=(22,22),facecolor='white')\n",
    "sns.color_palette(\"rocket\", as_cmap=True)  \n",
    "sns.heatmap(df_heatmap,annot = True,square=True, linewidths=1.5, cmap='rocket',mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0175ce5b",
   "metadata": {},
   "source": [
    "5.2 Kendall\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333e34e",
   "metadata": {},
   "source": [
    "La correlazione di Kendall invece segue un approccio diverso\n",
    " \n",
    "<ol>\n",
    "  <li>Ranking: si ordinano i dati secondo la variabile indipendente</li>\n",
    "  <li>Primo Compare: si confronta la prima variabile indipendente in cima alla tabella ordinata con tutti gli altri sample indipendenti x<sub>i+1</sub> > x<sub>i</sub> </li>\n",
    "  <li>Secondo Compare: si confronta la prima variabile dipendente associata alla prima variabile indip. con la successiva variabile dipendente verificando se y<sub>i+1</sub> > y<sub>i</sub> </li>\n",
    "  <li>Concorde o Discorde: se x<sub>i+1</sub> > x<sub>i</sub> e y<sub>i+1</sub> > y<sub>i</sub> sono entrambe vere si incrementa un valore <b>Nc</b> (numero di check concordi)   altrimenti s'incrementa <b>Nd</b> (numero di check discordi) </li> \n",
    "  <li>Si eseguono i passi 2 e 3 scorrendo la tabella verso il basso, fissando ogni volta una coppia di variabili dip. e indip. e confrontandole con tutte le altre</li> \n",
    "</ol>     \n",
    "\n",
    "Questo tipo di correlazione è perciò un po' più grossolana perchè non dà una percezione profonda della curva che stiamo analizzando ma il vantaggio è che la relazione potrebbe anche essere<b> non lineare</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4d52c",
   "metadata": {},
   "source": [
    "![KendalCorr.png](attachment:KendalCorr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = pd.DataFrame(df_data_1.corr(method='kendall'))\n",
    "mask=np.zeros_like(df_heatmap)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f,ax = plt.subplots(figsize=(22,22),facecolor='white')\n",
    "sns.color_palette(\"rocket\", as_cmap=True)  \n",
    "sns.heatmap(df_heatmap,annot = True,square=True, linewidths=1.5, cmap='rocket',mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ef516",
   "metadata": {},
   "source": [
    "5.3 Spearman\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a179a",
   "metadata": {},
   "source": [
    "La correlazione di Spearman è simile a quella di Pearson con la differenza che il sample da confrontare viene ordinato. Successivamente si calcola la distanza tra due set di campioni per mezzo di una semplice differenza portata poi al quadrato. La correlazione di Spearman è molto più sensibile alle variazioni dei dati rispetto alla correlazione di Kendall. Sotto un esempio:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e020176",
   "metadata": {},
   "source": [
    "![SpearmanCorr.png](attachment:SpearmanCorr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10adae",
   "metadata": {},
   "source": [
    "![SpearmanCorr2.PNG](attachment:SpearmanCorr2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2533f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heatmap = pd.DataFrame(df_data_1.corr(method='spearman'))\n",
    "mask=np.zeros_like(df_heatmap)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f,ax = plt.subplots(figsize=(22,22),facecolor='white')\n",
    "sns.color_palette(\"rocket\", as_cmap=True)  \n",
    "sns.heatmap(df_heatmap,annot = True,square=True, linewidths=1.5, cmap='rocket',mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fbdd0",
   "metadata": {},
   "source": [
    "6.STRING MANAGEMENT\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, Name , Surname in zip( df.index , df[\"Name\"] , df[\"Surname\"]):\n",
    "    df_index_res = df_data_1.index[(df_data_1[\"Name\"].str.contains(str(Surname))) & (df_data_1[\"Name\"].str.contains(str(Name)))]  \n",
    "    if len(df_index_res) == 1 and df_index_res != np.nan:\n",
    "        i_match = df_index_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b559581",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = re.findall('[0-9]+', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37862b",
   "metadata": {},
   "outputs": [],
   "source": [
    " l_index=[index for index in range(len(item)) if item.startswith('.',index) ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCabinPositionClass1.at[j,\"Name\"]=dfCabinPositionClass1[\"Split1\"].iloc[j].split(\" \")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3695d9",
   "metadata": {},
   "source": [
    "7.PLOT FUNCTIONS\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupplot(data, x , y , hue , n_subf , font_scale , wspace , palette , x_size , y_size ):\n",
    "    fig = plt.figure( figsize=(x_size, y_size))\n",
    "    subfigs = fig.subfigures(n_subf, 1, wspace=wspace)\n",
    "    sns.set(font_scale=font_scale)\n",
    "\n",
    "    for i in range(data[\"GroupSize\"].max()):\n",
    "        axs = subfigs[i].subplots(1, 3)\n",
    "        subfigs[i].suptitle(\" GroupSize :\"+str(i+1), fontsize='x-large')\n",
    "        for j , ax in enumerate(axs):\n",
    "            try:\n",
    "                sns.barplot(ax=ax, x = x, y= y, hue=hue , palette=palette,\n",
    "                                    data=data[(data[\"Pclass\"]==j+1) & (data[\"GroupSize\"]==i+1)])\n",
    "                plt.xticks(rotation=0)\n",
    "                if j==2:\n",
    "                    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "                ax.set_title(\"Class : \"+ str(j+1), fontsize=18)\n",
    "\n",
    "            except ValueError:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e041c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupplot( data = df_MeanByGroupAgeDeckNotSurv, x = 'Age Group' , y = 'SplitFare' ,hue = 'CabinDeck' ,\n",
    "          n_subf= 11 , font_scale = 1.5 , wspace = 3 , palette = palette , x_size = 22, y_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdc955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ee064",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.0)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.xticks(rotation=90)\n",
    "df_data_1['SplitFareBin'] = pd.cut(df_data_1['log10SplitFare'], bins=10)\n",
    "g = sns.barplot(x = 'SplitFareBin',y = 'Survived', data=df_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe0a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ca3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass','GroupSize','Age Group','CabinDeck']\n",
    "def GroupFare (data , features) :\n",
    "    for i in range(data[features[0]].max()):\n",
    "        df_Grouped_Count=data.query(features[0]+'=='+str(i+1)).groupby(features[1:4]).count().reset_index()\n",
    "        df_Grouped_Count[features[0]]=i+1\n",
    "        df_Grouped_fareMean=data.query(features[0]+'=='+str(i+1)).groupby(features[1:4]).SplitFare.mean().reset_index()\n",
    "        df_Grouped_fareMean[features[0]]=i+1\n",
    "        df_Grouped_fareStd=data.query(features[0]+'=='+str(i+1)).groupby(features[1:4]).SplitFare.std().reset_index()\n",
    "        df_Grouped_fareStd[features[0]]=i+1\n",
    "        if i==0 :\n",
    "            df_CountByGroupAgeDeck = df_Grouped_Count.copy() \n",
    "            df_MeanByGroupAgeDeck =  df_Grouped_fareMean.copy() \n",
    "            df_StdByGroupAgeDeck = df_Grouped_fareStd.copy()\n",
    "        if i>0 :\n",
    "            df_CountByGroupAgeDeck = pd.concat([df_CountByGroupAgeDeck, df_Grouped_Count], ignore_index=True)\n",
    "            df_MeanByGroupAgeDeck = pd.concat([df_MeanByGroupAgeDeck, df_Grouped_fareMean], ignore_index=True)\n",
    "            df_StdByGroupAgeDeck = pd.concat([df_StdByGroupAgeDeck, df_Grouped_fareStd], ignore_index=True)\n",
    "    return df_CountByGroupAgeDeck , df_MeanByGroupAgeDeck , df_StdByGroupAgeDeck\n",
    "\n",
    "df_CountByGroupAgeDeckNotSurv , df_MeanByGroupAgeDeckNotSurv , df_StdByGroupAgeDeckNotSurv = GroupFare(data = df_data_2 , features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aed8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "math.isnan(d_row_match['MeanFareUnk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(d_item['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474171bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FareResult_4 = df_FareResult_4.append(df3, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec620d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df_FareResult_4[l_col_newrow].loc[(df_FareResult_4['CabinDeck']==deck) &\n",
    "                                              (df_FareResult_4['GroupSize']==1) &\n",
    "                                              (df_FareResult_4['Pclass']==2) & \n",
    "                                              (df_FareResult_4['Age Group']==2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with unknown Cabin Deck \n",
    "df_FareResult_5 = df_FareResult_5.drop(df_FareResult_5 [(df_FareResult_5['CabinDeck']=='Unknown')].index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
